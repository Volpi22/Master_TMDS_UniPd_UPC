{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "91f5a09933026f90",
      "metadata": {
        "collapsed": false,
        "id": "91f5a09933026f90"
      },
      "source": [
        "# Install crucial libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e7a5374990a211da",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-22T08:32:11.371330Z",
          "start_time": "2025-05-22T08:32:11.363270Z"
        },
        "id": "e7a5374990a211da"
      },
      "outputs": [],
      "source": [
        "# !pip install langchain-community\n",
        "# !pip install langchain\n",
        "# !pip install pypdf\n",
        "# !pip install faiss-cpu\n",
        "# !pip install langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FFY3cMWYQ0As",
      "metadata": {
        "id": "FFY3cMWYQ0As"
      },
      "outputs": [],
      "source": [
        "# !pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b8698de8dbe84ad",
      "metadata": {
        "collapsed": false,
        "id": "9b8698de8dbe84ad"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "486238796eb913ed",
      "metadata": {
        "id": "486238796eb913ed"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from typing import Optional, List, Tuple\n",
        "from langchain_chroma import Chroma\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35c05faf6b52cbd",
      "metadata": {
        "collapsed": false,
        "id": "f35c05faf6b52cbd"
      },
      "source": [
        "\n",
        "## **Part 0: Choose and Test Your Topic Without a Knowledge Base**\n",
        "\n",
        "Before you load any external documents, you must **verify that your chosen topic needs a knowledge base** to improve answers. This ensures your RAG system solves a real gap in the model’s knowledge.\n",
        "\n",
        "###  **Steps:**\n",
        "\n",
        "1. **Choose a Topic (Tentative)**\n",
        "\n",
        "   * Pick a topic from 2024 or 2025 that you think is recent or under-documented.\n",
        "   * Example topics:\n",
        "\n",
        "     * A political decision (e.g., \"European Union climate laws in 2024\")\n",
        "     * A cultural trend (e.g., \"Music trends in early 2025\")\n",
        "\n",
        "2. **Formulate Question**\n",
        "\n",
        "   * Write down one factual, clear question about the topic.\n",
        "   * Aim for question that require up-to-date or specific knowledge.\n",
        "\n",
        "3. **Query the Model Directly**\n",
        "\n",
        "   * Use your LLM pipeline (without RAG) to ask this question.\n",
        "   * Collect the model’s answer and evaluate their quality:\n",
        "\n",
        "     * Are the answers incomplete?\n",
        "     * Are they outdated?\n",
        "     * Are they confident but wrong?\n",
        "     * Do they say *\"I don’t know\"*?\n",
        "\n",
        "---\n",
        "\n",
        "Why This Matters:\n",
        "\n",
        "This step ensures your RAG project is solving a **real information gap**, not just repeating what the model already knows.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c247de87f1159695",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2025-05-22T08:32:24.960957Z"
        },
        "id": "c247de87f1159695"
      },
      "outputs": [],
      "source": [
        "# The topic chosen is: The Festival of Sanremo 2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f0b2c2964b804dbd",
      "metadata": {
        "id": "f0b2c2964b804dbd"
      },
      "outputs": [],
      "source": [
        "# The question chosen is:\n",
        "question1 = \"In 2025 which number edition of the Sanremo Festival was conducted?\"\n",
        "question2= \"Who was the winner of the first night of the 2025 Sanremo Festival??\"\n",
        "question3= \"Who was the presenter of the 2025 Sanremo Festival?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "503e350d29a2a468",
      "metadata": {
        "collapsed": false,
        "id": "503e350d29a2a468"
      },
      "source": [
        "# **Part 1: Load a Custom PDF Knowledge Base**\n",
        "\n",
        "Find blog posts or wikipedia page with your topic and save information about it to a PDF file, and load it using `PyPDFLoader`. You may use other loaders not only pdf, but pdf loader is exactly the same as we used during lab.\n",
        "\n",
        "- Find informative content on your topic (Wikipedia page, blog post, article, etc.)\n",
        "- Save the page as a PDF file (you can use your browser’s print-to-PDF feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "49aa94dce815bc8a",
      "metadata": {
        "id": "49aa94dce815bc8a"
      },
      "outputs": [],
      "source": [
        "file_path = \"./Sanremo_2025_Wikipedia.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "RAW_KNOWLEDGE_BASE = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "flyDr1-zGxlJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flyDr1-zGxlJ",
        "outputId": "d1852331-dd7e-472e-efb4-236a2bd66b18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'producer': 'Skia/PDF m136',\n",
              " 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',\n",
              " 'creationdate': '2025-05-29T13:46:05+00:00',\n",
              " 'title': 'Sanremo Music Festival 2025 - Wikipedia',\n",
              " 'moddate': '2025-05-29T13:46:05+00:00',\n",
              " 'source': './Sanremo_2025_Wikipedia.pdf',\n",
              " 'total_pages': 21,\n",
              " 'page': 0,\n",
              " 'page_label': '1'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RAW_KNOWLEDGE_BASE[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e7acc5cf37e6117",
      "metadata": {
        "collapsed": false,
        "id": "6e7acc5cf37e6117"
      },
      "source": [
        "\n",
        "# **Part 2: Repeat the Lab with Your Own Knowledge Base + RAG Tuning**\n",
        "\n",
        "## **Goal:**\n",
        "\n",
        "Practice building a **RAG pipeline** and explore how **chunk size** and **chunk overlap** affect the quality of LLM answers to different questions.\n",
        "\n",
        "---\n",
        "\n",
        "## **What You Need to Do:**\n",
        "\n",
        "1. **Repeat the Lab Using Your PDF Knowledge Base**\n",
        "\n",
        "   * Use the PDF file you selected and loaded in Part 1.\n",
        "\n",
        "2. **Create 3 Different Questions**\n",
        "\n",
        "   * Design **three meaningful, specific questions** based on your topic.\n",
        "   * Each question must be clearly related to the content of your PDF.\n",
        "\n",
        "3. **Run RAG for Each Question with 3 Different Settings:**\n",
        "   For each question:\n",
        "\n",
        "   * Run the RAG pipeline **three times** using different settings for:\n",
        "\n",
        "     * `chunk_size` (e.g., 100, 300, 500)\n",
        "     * `chunk_overlap` (e.g., 0, 20, 50, 100)\n",
        "   * This means you will run a total of **9 tests** (3 questions × 3 settings each).\n",
        "\n",
        "\n",
        "4. **Answer Each Question Using an LLM**\n",
        "\n",
        "   * Use the loaded chunks and a retriever to find relevant parts.\n",
        "   * Pass the retrieved context to the LLM and generate an answer.\n",
        "   * You can use similar tools as we used in the Lab\n",
        "\n",
        "5. **Explain Your Results**\n",
        "   For each of the 3 questions:\n",
        "\n",
        "   * Write a short **description of the question** and **why you chose it**.\n",
        "   * **Compare the answers** you got using different settings.\n",
        "   * Reflect on:\n",
        "\n",
        "     * How answer quality changed with different `chunk_size` and `chunk_overlap`\n",
        "     * Which setting gave the most useful or accurate result\n",
        "     * Why you think it performed better/worse\n",
        "\n",
        "---\n",
        "\n",
        "## **Deliverables:**\n",
        "\n",
        "* Python code used for RAG pipeline (with different chunking settings)\n",
        "* PDF file from Part 1\n",
        "* A JSON file named rag_report_last_name_name_id.json containing your results:\n",
        "\n",
        "  * 3 questions with explanations\n",
        "  * Generated answers for each setting\n",
        "  * Comparison and reflection on the results\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "-XubtDCeMFJu",
      "metadata": {
        "id": "-XubtDCeMFJu"
      },
      "outputs": [],
      "source": [
        "def split_documents(chunk_size: int, chunk_overlap: int, knowledge_base: List, tokenizer_name: str) -> List:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "\n",
        "    docs_processed = text_splitter.split_documents(knowledge_base)\n",
        "\n",
        "    return docs_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "39be2ec371b6c408",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4016c530e8bc4661a4a74a15613cce7d",
            "4190e867005b4f9d96c883de41a30ba6",
            "44834fd793a14a26a50f6d18d987d905",
            "00cf643055d6413386bb0d95b6d20946",
            "1972ec349dd247bf9c6cafe7a2472b34",
            "5da54e5aae084143bf7fbba0e8d6ae04",
            "b9e02a599438492e8fa1a0c501f9704c",
            "4ea5a548d47540feb96c27ab0d94692d",
            "41b12d4e340044a6a9df9b58b9a254f8",
            "9c41fbd478d7468e9a3ef62984853275",
            "d3de6546cd0b4f12b446272f319ecfc8"
          ]
        },
        "id": "39be2ec371b6c408",
        "outputId": "4c6604fb-ef5c-4cb4-da75-f6f37a2434c5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4016c530e8bc4661a4a74a15613cce7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
        "docs_processed = split_documents(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "READER_MODEL_NAME = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(READER_MODEL_NAME, quantization_config=bnb_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        ")\n",
        "\n",
        "prompt_in_chat_format = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"Using the information contained in the context, give a comprehensive answer to the question. Respond only to the question asked, response should be concise and relevant to the question. If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context: {context}\n",
        "        ---\n",
        "        Now here is the question you need to answer.\n",
        "        Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "\n",
        "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "    prompt_in_chat_format,\n",
        "    tokenize=False, # Return a string, not token IDs\n",
        "    add_generation_prompt=True # Ensures model knows where to start generating\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "GD25QWH8XdVV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD25QWH8XdVV",
        "outputId": "c9cabe25-3749-492e-9638-179d7baf32c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': '\\n   A) The twenty-fifth\\n   B) The thirty-first\\n   C) Both A and B are correct.\\n   D) None of the above is correct.\\n   \\n   Answer: C) Both A and B are correct, as it refers to both \"Sanremo Music Festival\" (the twenty-fifth edition in this context), and also specifically mentions that there were three editions held during World War II between 1935–40, making a total count up until 2025 inclusive would be at least forty-one if we consider each year\\'s event separately from those wartime years. However, since they occurred within one calendar year but not consecutively due to war disruzioni, counting them individually may lead to confusion without additional historical information specifying how many times the festival took place annually outside these specific WWII occurrences. Therefore, for an accurate answer based on provided data alone, only option A can be confirmed with certainty—it marks its twentieth anniversary celebration in 2025. Option B could potentially refer to another unrelated annual music festival or different events altogether.'}]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "READER_LLM(question1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "DZW42wiiXfLU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZW42wiiXfLU",
        "outputId": "5a36076e-180d-49f1-f6e7-0b9d297ad601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': '\\nOptions: (A) Elena Ferrante (B) Enzo G. Ceragioli (C) Antonio Amore (D) Luca Moretti'}]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "READER_LLM(question2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "yayvvZovXgh2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yayvvZovXgh2",
        "outputId": "e57c1074-eac6-4c4f-d382-d27abc2dbb7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'generated_text': \"\\n   A) Maria Laura Rinaldi\\n   B) Antonello Venditti\\n   C) Gianni Morandi\\n   D) Lucio Dalla\\n   \\n   Answer: The question does not provide information about who presented in 2025. Please refer to official sources for this data as it may vary each year and could be different from past years' winners or notable artists like those listed above, which are known but do not necessarily correspond with festival hosts.\"}]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "READER_LLM(question3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uy0AgsL0RS4u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Uy0AgsL0RS4u",
        "outputId": "271d27cc-342d-46ee-b14d-5bdd99393b0f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The sixth edition of the Sanremo Festival took place in 2025.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(question1), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question1, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer1_1 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer1_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2Bt_tjSBSL3p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "2Bt_tjSBSL3p",
        "outputId": "965dce07-feb1-4bd2-ec73-7c5da9539bc4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" The document provided does not contain any information about the winners of the first or second nights at the 2025 Sanremo Festival; it solely discusses performances by Italy's representatives for that year's Eurovision contest without mentioning specific results or names associated with those initial events. Therefore, I am unable to provide an answer based on this context alone.\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question2, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer1_2 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer1_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "m4H4J6stR-ji",
      "metadata": {
        "id": "m4H4J6stR-ji"
      },
      "outputs": [],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question3, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer1_3 = READER_LLM(final_prompt)[0][\"generated_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "LYYMmpBkVrrB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "LYYMmpBkVrrB",
        "outputId": "36977413-6ab8-4d21-8d8c-24c6f941117b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The document does not provide any specific names for the presenters at the 2025 Sanremo Festival. It mentions that Italy participated with artists such as Mirko Onofrio and Riccardo Zangirolami performing during the event but lacks details about who hosted or presented it. Therefore, I cannot provide an accurate answer based on this context alone.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer1_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "YAU2ftDyTXpA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YAU2ftDyTXpA",
        "outputId": "c3c0bf04-3425-42db-f119-b9d21e013265"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" The provided text does not contain any specific details about editions or years related to the Sanremo Festival for the year 2025; therefore, it's impossible to determine this based solely on the given document excerpts.\""
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question1, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer2_1 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer2_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7lOsHuQYTeNv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "7lOsHuQYTeNv",
        "outputId": "e3650929-690a-4a43-80df-13b1e9cd9791"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" The document provided does not contain any specific details about winners or results for individual evenings at the 2025 Sanremo Festival; it simply lists performers (Mirko Onofrio and Riccardo Zangirolami) who appeared during the event's fourth evening without mentioning that they were competitors or indicating their performance order. Therefore, based on this text alone, I am unable to determine the winner of the first night.\""
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question2, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer2_2 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer2_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "PbKzrdDVTg2M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PbKzrdDVTg2M",
        "outputId": "4eb8164c-17ac-41ab-a745-164707bc8b6c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The document does not provide any specific name for the presenter at the 2025 Sanremo Festival; it only mentions that Italy participated with artists such as Mirko Onofrio and Riccardo Zangirolami performing their covers without a live orchestra due to being sung a capella. Therefore, I am unable to determine who presented the event based solely on this provided text.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question3, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer2_3 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer2_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4KPk-AsHTj79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "4KPk-AsHTj79",
        "outputId": "8cf5b222-fe6c-40bd-951c-3b1db800bc93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The extracted documents provided no specific details about any \"Sanremo Festival\" or its editions for the year 2025; they solely discuss Italy\\'s participation in the Eurovision Song Contest that same year with performers Mirko Onofrio and Riccardo Zangirolami performing without a live conductor due to it being an a capella performance. Therefore, I cannot provide an answer based on this context regarding the Sanremo Festival.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question1, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer3_1 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer3_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "GxVuOkAKTpDj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GxVuOkAKTpDj",
        "outputId": "3b69ffce-e781-4779-8918-ba385e7a1830"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The extracted documents provided no specific details about who won the first night of the 2025 Sanremo Festival; therefore, I am unable to provide that information based solely on this context.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question2, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer3_2 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer3_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "S0tpv_4cTrHA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "S0tpv_4cTrHA",
        "outputId": "719dceaa-7441-4681-a439-6a42a3057bc9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" The extracted documents provided no specific mention about who presented the 2025 San Remo Festival; they solely focus on Italy's participation at the Eurovision Song Contest that year with details regarding performers but lack any reference or detail related to festival presentation personnel. Therefore, based on this document alone we can’t determine the presenter for the event.\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_processed = split_documents(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100,\n",
        "    knowledge_base=RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "vector_store = Chroma.from_documents(\n",
        "    docs_processed,\n",
        "    embedding_model,\n",
        "    persist_directory=\"db9\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embedding_model.embed_query(\"What are results of European Election in 2024?\"), k=4\n",
        ")\n",
        "\n",
        "retrieved_docs_text = [doc.page_content for doc in results]  # We only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join([f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)])\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(question=question3, context=context)\n",
        "\n",
        "# Redact an answer\n",
        "answer3_3 = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "answer3_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8db167ca254763a",
      "metadata": {
        "collapsed": false,
        "id": "8db167ca254763a"
      },
      "source": [
        "### Template for your resulting json file with report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eef0bdf7e079c909",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-28T22:36:51.042915Z",
          "start_time": "2025-05-28T22:36:51.040385Z"
        },
        "id": "eef0bdf7e079c909"
      },
      "outputs": [],
      "source": [
        "your_results_dict = {\n",
        "  \"topic\": \"Sanremo Festival 2025\",\n",
        "  \"question\":\"In 2025 which number edition of the Sanremo Festival was conducted?\",\n",
        "  \"answer\":\" A) The twenty-fifth\\n   B) The thirty-first\\n   C) Both A and B are correct.\\n   D) None of the above is correct.\\n   Answer: C) Both A and B are correct, as it refers to both Sanremo Music Festival (the twenty-fifth edition in this context), and also specifically mentions that there were three editions held during World War II between 1935–40, making a total count up until 2025 inclusive would be at least forty-one if we consider each year\\'s event separately from those wartime years. However, since they occurred within one calendar year but not consecutively due to war disruzioni, counting them individually may lead to confusion without additional historical information specifying how many times the festival took place annually outside these specific WWII occurrences. Therefore, for an accurate answer based on provided data alone, only option A can be confirmed with certainty—it marks its twentieth anniversary celebration in 2025. Option B could potentially refer to another unrelated annual music festival or different events altogether.\",\n",
        "  \"rag\": [\n",
        "    {\n",
        "      \"question\": \"In 2025 which number edition of the Sanremo Festival was conducted?\",\n",
        "      \"reason\": \"Because was the 75 edition, an important milestone\",\n",
        "      \"experiments\": [\n",
        "        {\n",
        "          \"chunk_size\": \"100\",\n",
        "          \"chunk_overlap\": \"20\",\n",
        "          \"answer\": \"The sixth edition of the Sanremo Festival took place in 2025.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"100\",\n",
        "          \"chunk_overlap\": \"20\",\n",
        "          \"answer\": \"The document provided does not contain any information about the winners of the first or second nights at the 2025 Sanremo Festival; it solely discusses performances by Italy's representatives for that year's Eurovision contest without mentioning specific results or names associated with those initial events. Therefore, I am unable to provide an answer based on this context alone.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"100\",\n",
        "          \"chunk_overlap\": \"20\",\n",
        "          \"answer\": \"The document does not provide any specific names for the presenters at the 2025 Sanremo Festival. It mentions that Italy participated with artists such as Mirko Onofrio and Riccardo Zangirolami performing during the event but lacks details about who hosted or presented it. Therefore, I cannot provide an accurate answer based on this context alone.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"question\": \"Who was the winner of the first night of the 2025 Sanremo Festival?\",\n",
        "      \"reason\": \"Explain why this question is meaningful to your topic\",\n",
        "      \"experiments\": [\n",
        "        {\n",
        "          \"chunk_size\": \"300\",\n",
        "          \"chunk_overlap\": \"50\",\n",
        "          \"answer\": \"The provided text does not contain any specific details about editions or years related to the Sanremo Festival for the year 2025; therefore, it's impossible to determine this based solely on the given document excerpts.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"300\",\n",
        "          \"chunk_overlap\": \"50\",\n",
        "          \"answer\": \"The document provided does not contain any specific details about winners or results for individual evenings at the 2025 Sanremo Festival; it simply lists performers (Mirko Onofrio and Riccardo Zangirolami) who appeared during the event's fourth evening without mentioning that they were competitors or indicating their performance order. Therefore, based on this text alone, I am unable to determine the winner of the first night.\",\n",
        "          \"reflection\": \" \"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"300\",\n",
        "          \"chunk_overlap\": \"50\",\n",
        "          \"answer\": \"The document does not provide any specific name for the presenter at the 2025 Sanremo Festival; it only mentions that Italy participated with artists such as Mirko Onofrio and Riccardo Zangirolami performing their covers without a live orchestra due to being sung a capella. Therefore, I am unable to determine who presented the event based solely on this provided text.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"question\": \"Who was the presenter of the 2025 Sanremo Festival?\",\n",
        "      \"reason\": \"Explain why this question is useful or interesting\",\n",
        "      \"experiments\": [\n",
        "        {\n",
        "          \"chunk_size\": \"500\",\n",
        "          \"chunk_overlap\": \"100\",\n",
        "          \"answer\": \"The extracted documents provided no specific details about any Sanremo Festival or its editions for the year 2025; they solely discuss Italy\\'s participation in the Eurovision Song Contest that same year with performers Mirko Onofrio and Riccardo Zangirolami performing without a live conductor due to it being an a capella performance. Therefore, I cannot provide an answer based on this context regarding the Sanremo Festival.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"500\",\n",
        "          \"chunk_overlap\": \"100\",\n",
        "          \"answer\": \"The extracted documents provided no specific details about who won the first night of the 2025 Sanremo Festival; therefore, I am unable to provide that information based solely on this context.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        },\n",
        "        {\n",
        "          \"chunk_size\": \"500\",\n",
        "          \"chunk_overlap\": \"100\",\n",
        "          \"answer\": \"The extracted documents provided no specific mention about who presented the 2025 San Remo Festival; they solely focus on Italy's participation at the Eurovision Song Contest that year with details regarding performers but lack any reference or detail related to festival presentation personnel. Therefore, based on this document alone we can’t determine the presenter for the event.\",\n",
        "          \"reflection\": \"The structure of the PDF and the specificity of the questions prevented the model from answering correctly and made it difficult to locate the relevant information within the file.\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "50084e2063ae7fb0",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-05-28T22:36:51.344609Z",
          "start_time": "2025-05-28T22:36:51.341408Z"
        },
        "id": "50084e2063ae7fb0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\"rag_report_Davide_Volpi_2140728.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(your_results_dict, f, indent=2, ensure_ascii=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00cf643055d6413386bb0d95b6d20946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c41fbd478d7468e9a3ef62984853275",
            "placeholder": "​",
            "style": "IPY_MODEL_d3de6546cd0b4f12b446272f319ecfc8",
            "value": " 2/2 [00:41&lt;00:00, 19.79s/it]"
          }
        },
        "1972ec349dd247bf9c6cafe7a2472b34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4016c530e8bc4661a4a74a15613cce7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4190e867005b4f9d96c883de41a30ba6",
              "IPY_MODEL_44834fd793a14a26a50f6d18d987d905",
              "IPY_MODEL_00cf643055d6413386bb0d95b6d20946"
            ],
            "layout": "IPY_MODEL_1972ec349dd247bf9c6cafe7a2472b34"
          }
        },
        "4190e867005b4f9d96c883de41a30ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da54e5aae084143bf7fbba0e8d6ae04",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e02a599438492e8fa1a0c501f9704c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "41b12d4e340044a6a9df9b58b9a254f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44834fd793a14a26a50f6d18d987d905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea5a548d47540feb96c27ab0d94692d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41b12d4e340044a6a9df9b58b9a254f8",
            "value": 2
          }
        },
        "4ea5a548d47540feb96c27ab0d94692d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da54e5aae084143bf7fbba0e8d6ae04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c41fbd478d7468e9a3ef62984853275": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e02a599438492e8fa1a0c501f9704c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3de6546cd0b4f12b446272f319ecfc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
