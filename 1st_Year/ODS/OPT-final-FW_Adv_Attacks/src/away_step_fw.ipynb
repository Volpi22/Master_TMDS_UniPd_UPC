{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d23b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def awaystep_fw(\n",
    "    objective_fun, \n",
    "    gradient_fun, \n",
    "    LMO, \n",
    "    x0, \n",
    "    hyperparams={\"max_iterations\": 20, \"tolerance\": 1e-6}\n",
    "):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        - objective_fun (callable): Function f(x) to minimize (or maximize if sign=-1).\n",
    "        - gradient_fun (callable): Gradient of f(x).\n",
    "        - projection_operator (callable): Projection onto the feasible set (e.g., Lâˆž-ball).\n",
    "        - x0 (np.ndarray): Initial feasible point.\n",
    "        - hyperparams (dict): Dictionary with hyperparameters:\n",
    "            - \"max_iterations\" (int): Maximum number of iterations.\n",
    "            - \"tolerance\" (float): Tolerance on gradient norm.\n",
    "    Outputs:\n",
    "        - x_t (np.ndarray): Final solution.\n",
    "        - t (int): Number of iterations performed.\n",
    "        - history (dict): Contains 'objective' and 'gradient_norm'.\n",
    "    \"\"\"\n",
    "    # Defining the parameters\n",
    "    x_t = x0.copy().astype(np.float64)\n",
    "    max_iterations = hyperparams[\"max_iterations\"]\n",
    "    tolerance = hyperparams[\"tolerance\"]\n",
    "\n",
    "    # Defining the active set S and weights alpha_t\n",
    "    active_set = [x0.copy()]\n",
    "    weights = np.array([1.0])\n",
    "\n",
    "    # History trackers\n",
    "    history = {'objective': [], 'gap': [], 'gradient': []}\n",
    "\n",
    "    # Starting the Away-step Frank-Wolfe iterations\n",
    "    for t in range(1, max_iterations + 1):\n",
    "\n",
    "        # Compute the loss and gradient at the current point\n",
    "        objective_t = objective_fun(x_t)\n",
    "        grad_t = gradient_fun(x_t)\n",
    "\n",
    "        # Compute the FW candidate direction\n",
    "        s_t = LMO(grad_t)\n",
    "        d_t_FW = s_t - x_t\n",
    "\n",
    "        # Compute the FW duality gap\n",
    "        gap_t_FW = - grad_t @ d_t_FW\n",
    "\n",
    "        # Compute the away vertex\n",
    "        v_scores = np.array([grad_t @ v for v in active_set])\n",
    "        v_t_idx = np.argmax(v_scores)\n",
    "        v_t = active_set[v_t_idx]\n",
    "        \n",
    "        # Compute the Away candidate direction\n",
    "        d_t_Away = x_t - v_t \n",
    "\n",
    "        # Compute the Away duality gap\n",
    "        gap_t_Away = - grad_t @ d_t_Away \n",
    "\n",
    "        # Store history\n",
    "        history['gradient'].append(grad_t)\n",
    "        history['objective'].append(objective_t)\n",
    "        history['gap'].append(max(gap_t_FW, gap_t_Away))\n",
    "\n",
    "        # Check for convergence\n",
    "        if gap_t_FW <= tolerance:\n",
    "            print(f\"Duality gap below tolerance at iteration {t}: {gap_t_FW}\")\n",
    "            break\n",
    "\n",
    "        # Choose between FW step and Away step based on the duality gap\n",
    "        if gap_t_FW >= gap_t_Away:\n",
    "            selected_direction = 'FW'\n",
    "            selected_d_t = d_t_FW\n",
    "            gamma_max = 1.0\n",
    "        else:\n",
    "            selected_direction = 'Away'\n",
    "            selected_d_t = d_t_Away\n",
    "            gamma_max = weights[v_t_idx] / (1.0 - weights[v_t_idx] + 1e-10)\n",
    "\n",
    "        # Determine step size with diminishing step size rule\n",
    "        gamma_t = min(2 / (t + 2), gamma_max)\n",
    "\n",
    "        # Compute the next step\n",
    "        x_t += gamma_t * selected_d_t\n",
    "\n",
    "        # Update active set and weights based when choose FW\n",
    "        if selected_direction == 'FW':\n",
    "            if gamma_t == gamma_max:\n",
    "                # If we take a full step, we can reset the active set\n",
    "                active_set = [s_t]\n",
    "                weights = np.array([1.0])\n",
    "            else:\n",
    "                is_in_active_set = any(np.all(s_t == v) for v in active_set)\n",
    "                # If we take a partial step, we need to update the active set\n",
    "                if not is_in_active_set:\n",
    "                    active_set.append(s_t)\n",
    "                    weights = np.append(weights, gamma_t)\n",
    "                else:\n",
    "                    # Update the weight of s_t in the active set\n",
    "                    s_t_idx = active_set.index(s_t)\n",
    "                    weights *= (1.0 - gamma_t)\n",
    "                    weights[s_t_idx] += gamma_t\n",
    "\n",
    "        # Update active set and weights based when choose Away Step\n",
    "        if selected_direction == \"Away\":\n",
    "            if gamma_t == gamma_max:\n",
    "                # Remove v_t from active set\n",
    "                active_set.pop(v_t_idx)\n",
    "                weights = np.delete(weights, v_t_idx) \n",
    "            else:\n",
    "                 # Update weight of v_t\n",
    "                weights *= (1.0 + gamma_t)\n",
    "                weights[v_t_idx] -= gamma_t\n",
    "\n",
    "    return x_t, t, history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
